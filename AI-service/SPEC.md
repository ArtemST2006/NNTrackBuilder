Задача: реализоавать микросервис ИИ

Микросервис как consumer: читает сообщения из топика ai.makePoints.request

Микросервис как producer: публикует сообщения в топик ai.makePoints.response

Микросервис читает данные, создаёт промпт и кидает нейронке. Нейронка выдаёт ответ, микр составляет json и публикует обратно в кафку

Микросервис должен быть идемпотентным (готов к получению дубликатов, из за настройки кафки at least one)

входные данные(чтение из топика)
```commandline
{
    "depends": "profile"
    "user_id": int,
    "task_id": string,
    "profile": string # пустой будет
    "input_data": {
        "category": list
        "time": float # вреям которое пользователь готов потратить на прогулку
        "cords": str # либо скидыват координты
        "place": str № либо скидывает адрес
    }
}


Пример со всеми категориями:
{
	"depends": "profile",
	"task_id": "9d58964e-f822-4088-a340-ee41044be734",
	"user_id": 2,
	"profile": "",
	"input_data": {
		"category": [
			"parks",
			"architecture",
			"museums",
			"views",
			"shops",
			"all",
			"street_art",
			"cafes"
		],
		"time": 3.0,
		"cords": "",
		"place": ""
	}
}
```

выходные данные(публикация в топик) 
```commandline
{
    "user_id": int,
    "task_id": string,
    "output": [
        {
            спроси у дениса в каком формате нейронка будет выдавать ответ
            (должны быть координаты мест + описание)
        }
    ]
    "description": string,
    "time": float,
    "long": float,
    "advice": string,
}
```

важно публиковать соо без ключа.
Кафка-клиент aiokafka. Можешь делать как на API-Gateway. 

И последнее - это вопрос с синхронностью. У на сервере будет запускаться RAG система. Спроси у Дениса насколько долго 
она будет работать. Если долго, то это шляпа для питона и надо распаралеливать процессы, чтобы сервис не застывал.

Есть вариант запустить несколько реплик этого сервиса в разных контейнерах, но это крайний случай. 
Вообщем посмотри как можно эту проблему решить
